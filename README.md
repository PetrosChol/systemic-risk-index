# Systemic Risk Analysis Dashboard

![Python Version](https://img.shields.io/badge/python-3.12+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.46.1-FF4B4B.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)

An interactive dashboard to monitor systemic risk in financial markets using a custom-built index and Generative AI-powered analysis.

## ğŸš€ Features

-   **Dynamic Systemic Risk Index (SRI):** A proprietary index constructed using Principal Component Analysis (PCA) on key risk indicators, scaled historically for context.
-   **Interactive Dashboard:** A fluid Streamlit application for visualizing the SRI and its underlying components over time.
-   **Generative AI Summaries:** On-demand economic outlooks generated by leading AI models (from Google, OpenAI, Anthropic, and Groq).
-   **Automated Data Pipeline:** Fetches and preprocesses the latest data from FRED and Yahoo Finance with a single click.

## ğŸ–¼ï¸ Screenshot

![Dashboard Screenshot](images/Screenshot.png)

## ğŸ› ï¸ How It Works

The core of this project is the **Systemic Risk Index (SRI)**, which provides a historical measure of financial market stress.

1.  **Data Collection:** Key financial stress indicators are collected:
   -   `VIX`: Equity Market Volatility
   -   `MOVE`: Treasury Bond Market Volatility
   -   `BAMLC0A0CMEY`: US Corporate Bond Yield (Credit Risk)
2.  **Data Standardization:** The indicators are standardized to ensure each contributes equally to the analysis.
3.  **Principal Component Analysis (PCA):** PCA is applied to identify the primary axis of shared variance among the indicators.
4.  **Index Construction:** The first principal component (PC1) is extracted, representing the most significant combined movement of the risk factors.
5.  **Historical Scaling:** The final index is scaled from 0-100 over the **entire historical dataset**. This ensures that today's SRI value is directly comparable to risk levels during major past events like the 2008 crisis or the 2020 pandemic.

## ğŸ Getting Started

### Prerequisites

-   Python 3.12+
-   `uv` - A high-performance Python package installer and resolver.
    -   If you don't have it: https://docs.astral.sh/uv/getting-started/installation/

### Installation & Setup

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/PetrosChol/systemic-risk-index.git
    cd systemic-risk-index
    ```

2.  **Install dependencies using `uv`:**
    ```bash
    uv sync
    ```

3.  **Configure Environment Variables:**
    This project requires an API key from the Federal Reserve Economic Data (FRED).
    Also requires an OpenAI, Anthropic, Gemini or Groq API key for Generative AI model access.
    -   Sign up for a free API key at [FRED](https://fred.stlouisfed.org/).
    -   Sign up for an API key at [OpenAI](https://platform.openai.com/api-keys).
    -   Sign up for an API key at [Anthropic](https://console.anthropic.com/settings/keys).
    -   Sign up for an API key at [Gemini](https://aistudio.google.com/apikey).
    -   Sign up for a free API key at [Groq](https://console.groq.com/keys).

    -   Rename the file named `.env.example` in the project's root directory to `.env`.
    -   Add your FRED API key to this file:
        ```env
        # .env
        FRED_API_KEY="YOUR_API_KEY_HERE"
        OPENAI_API_KEY="YOUR_API_KEY_HERE"
        ANTHROPIC_API_KEY="YOUR_API_KEY_HERE"
        GEMINI_API_KEY="YOUR_API_KEY_HERE"
        GROQ_API_KEY="YOUR_API_KEY_HERE"
        ```
    It is not necessary to set all keys, you can use only the ones you need. Fred is required, the others are optional.

### Running the Application

1.  **Launch the Streamlit dashboard:**
    ```bash
    uv run streamlit run .\gen_ai\app.py
    ```

2.  **Download the data:**
    -   Upon first launch, the app will prompt you that data is missing.
    -   Use the **"Download Fresh Risk Data"** button in the sidebar to automatically fetch, process, and save the necessary data.

3.  **Start Analyzing!**
    -   View the Systemic Risk Index and its components.
    -   Select a Generative AI model from the sidebar and click "Generate Summary" to get an AI-powered analysis.

## ğŸ“‚ Project Structure

```plaintext
systemic-risk-index/
â”œâ”€â”€ data/ # Stores the risk_factors.csv data file
â”œâ”€â”€ gen_ai/ # Source code for the Streamlit app and AI components
â”‚ â”œâ”€â”€ app.py # The main Streamlit application
â”‚ â”œâ”€â”€ index_construction.py # Logic for downloading data and constructing the SRI
â”‚ â”œâ”€â”€ models.py # AI model provider configurations
â”‚ â””â”€â”€ summary_gen.py # AI summary generation logic and system prompt
â”œâ”€â”€ notebooks/ # Jupyter notebooks for exploration and development
â”œâ”€â”€ plots/ # For storing saved plots or screenshots
â”œâ”€â”€ .env.example # (You must rename this to .env) For API keys
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ .pyproject.toml # Project metadata and dependencies
â””â”€â”€ .python-version # Specifies the Python version
â””â”€â”€ .streamlit/ # Streamlit configuration files
â”‚   â””â”€â”€ config.toml # Streamlit configuration
â””â”€â”€ uv.lock # Dependency lock file
```


## ğŸ¤– Tech Stack

### Core Application Stack

-   **Web App & Plotting:** `Streamlit`, `Plotly`
-   **Data Analysis & ML:** `Pandas`, `NumPy`, `Scikit-learn`
-   **Data Sourcing:** `yfinance`, `fredapi`
-   **Generative AI Framework:** `LangChain`
-   **AI Model Integrations:** `langchain-openai`, `langchain-anthropic`, `langchain-google-genai`, `langchain-groq`
-   **Configuration:** `python-dotenv`

### Development Environment

-   **Package Management:** `uv`
-   **Code Formatting:** `black`
-   **Jupyter/Notebooks:** `ipykernel`, `nbformat`, `tabulate`

Dependencies are managed in the `pyproject.toml` file.